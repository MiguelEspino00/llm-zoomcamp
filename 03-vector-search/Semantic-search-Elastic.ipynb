{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ab3366-9e0b-4229-90e3-9f82ed4dc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e37990-3564-44f2-bdea-cbac291da8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3852c4-3b52-4f8e-8236-105ca857f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0ee70e-ba8e-455f-b147-7fcf2dbca18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers==2.7.0\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers==2.7.0)\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (2.3.0+cpu)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (1.5.0)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (1.13.1)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence_transformers==2.7.0)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.10/site-packages (from sentence_transformers==2.7.0) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.7.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.7.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.7.0) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers==2.7.0) (2024.5.15)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence_transformers==2.7.0)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers==2.7.0)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.7.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.7.0) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers==2.7.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.7.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers==2.7.0) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.24.5 safetensors-0.4.3 sentence_transformers-2.7.0 tokenizers-0.19.1 transformers-4.43.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7b0e7b-975d-4a7f-80df-edda2cd0c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a new library compared to the previous modules. \n",
    "# Please perform \"pip install sentence_transformers==2.7.0\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# if you get an error do the following:\n",
    "# 1. Uninstall numpy \n",
    "# 2. Uninstall torch\n",
    "# 3. pip install numpy==1.26.4\n",
    "# 4. pip install torch\n",
    "# run the above cell, it should work\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e19d30-1a18-4a1a-8eb9-4f6135e8512d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e807fe9-a86e-43af-8570-fc9e78e9aba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.encode(\"This is a simple sentence\"))  #Each model has a different length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8015f4-b85c-4895-8222-b7d85483a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created the dense vector using the pre-trained model\n",
    "operations = []\n",
    "for doc in documents:\n",
    "    # Transforming the title into an embedding using the model\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f50e6-18e2-424d-9627-c23170bd5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a26b01f8-8c13-4a29-8e4d-c4d8d92b6c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'e183ae6a1c34', 'cluster_name': 'docker-cluster', 'cluster_uuid': '-32sOrMLRIKYbiMOpOtnDA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c13ede-c7c6-4f77-bd06-f6617981930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} ,\n",
    "            \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b783b6-46de-4fc0-9668-623ba634228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True) #Looks like a Best Practice\n",
    "es_client.indices.create(index = index_name, body = index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff7c5b13-9263-4186-bac4-9768283ea831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in operations:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document = doc)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "259bfd77-c15c-41b5-b22e-747f87915750",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"windows or mac?\"\n",
    "vectorize = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7707986-a6c6-4eae-a923-8c53a4172560",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": vectorize,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df323f68-cd82-4f3b-aecf-9cae863fce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es_client.search(index=index_name, knn=query, source=[\"text\", \"section\", \"question\", \"course\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1ee800a-b710-4a37-8808-a00e6fc3460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': 'ijj8HJEBfHw0c1uW5kxX',\n",
       "  '_score': 0.7147919,\n",
       "  '_source': {'question': 'Environment - Is the course [Windows/mac/Linux/...] friendly?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'nTj9HJEBfHw0c1uWPU8C',\n",
       "  '_score': 0.61347336,\n",
       "  '_source': {'question': 'WSL instructions',\n",
       "   'course': 'mlops-zoomcamp',\n",
       "   'section': 'Module 1: Introduction',\n",
       "   'text': 'If you wish to use WSL on your windows machine, here are the setup instructions:\\nCommand: Sudo apt install wget\\nGet Anaconda download address here. wget <download address>\\nTurn on Docker Desktop WFree Download | AnacondaSL2\\nCommand: git clone <github repository address>\\nVSCODE on WSL\\nJupyter: pip3 install jupyter\\nAdded by Gregory Morris (gwm1980@gmail.com)\\nAll in all softwares at one shop:\\nYou can use anaconda which has all built in services like pycharm, jupyter\\nAdded by Khaja Zaffer (khajazaffer@aln.iseg.ulisboa.pt)\\nFor windows “wsl --install” in Powershell\\nAdded by Vadim Surin (vdmsurin@gmai.com)'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'Xjj9HJEBfHw0c1uWGU5v',\n",
       "  '_score': 0.6055558,\n",
       "  '_source': {'question': \"The answer I get for one of the homework questions doesn't match any of the options. What should I do?\",\n",
       "   'course': 'machine-learning-zoomcamp',\n",
       "   'section': '2. Machine Learning for Regression',\n",
       "   'text': 'That’s normal. We all have different environments: our computers have different versions of OS and different versions of libraries — even different versions of Python.\\nIf it’s the case, just select the option that’s closest to your answer'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'tzj9HJEBfHw0c1uWI04W',\n",
       "  '_score': 0.60289603,\n",
       "  '_source': {'question': 'How to install WSL on Windows 10 and 11 ?',\n",
       "   'course': 'machine-learning-zoomcamp',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'text': 'It is quite simple, and you can follow these instructions here:\\nhttps://www.youtube.com/watch?v=qYlgUDKKK5A&ab_channel=NeuralNine\\nMake sure that you have “Virtual Machine Platform” feature activated in your Windows “Features”. To do that, search “features” in the research bar and see if the checkbox is selected. You also need to make sure that your system (in the bios) is able to virtualize. This is usually the case.\\nIn the Microsoft Store: look for ‘Ubuntu’ or ‘Debian’ (or any linux distribution you want) and install it\\nOnce it is downloaded, open the app and choose a username and a password (secured one). When you type your password, nothing will show in the window, which is normal: the writing is invisible.\\nYou are now inside of your linux system. You can test some commands such as “pwd”. You are not in your Windows system.\\nTo go to your windows system: you need to go back two times with cd ../.. And then go to the “mnt” directory with cd mnt. If you list here your files, you will see your disks. You can move to the desired folder, for example here I moved to the ML_Zoomcamp folder:\\nPython should be already installed but you can check it by running sudo apt install python3 command.\\nYou can make your actual folder your default folder when you open your Ubuntu terminal with this command : echo \"cd ../../mnt/your/folder/path\" >> ~/.bashrc\\nYou can disable bell sounds (when you type something that does not exist for example) by modifying the inputrc file with this command: sudo vim /etc/inputrc\\nYou have to uncomment the set bell-style none line -> to do that, press the “i” keyboard letter (for insert) and go with your keyboard to this line. Delete the # and then press the Escape keyboard touch and finally press “:wq” to write (it saves your modifications) then quit.\\nYou can check that your modifications are taken into account by opening a new terminal (you can pin it to your task bar so you do not have to go to the Microsoft app each time).\\nYou will need to install pip by running this command sudo apt install python3-pip\\nNB: I had this error message when trying to install pipenv (https://github.com/microsoft/WSL/issues/5663):\\n/sbin/ldconfig.real: Can\\'t link /usr/lib/wsl/lib/libnvoptix_loader.so.1 to libnvoptix.so.1\\n/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link\\nSo I had to create the following symbolic link:\\nsudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/lib64/libcuda.so\\n(Mélanie Fouesnard)'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'ezj8HJEBfHw0c1uW5Eyv',\n",
       "  '_score': 0.5985867,\n",
       "  '_source': {'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "013e0663-0816-4301-9807-10de751526cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included \"knn\" in the search query (to perform a semantic search) along with the filter  \n",
    "knn_query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": vectorize,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50991e4a-0a4b-47ec-a14a-a2ee7221fb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': 'ijj8HJEBfHw0c1uW5kxX',\n",
       "  '_score': 11.614713,\n",
       "  '_source': {'question': 'Environment - Is the course [Windows/mac/Linux/...] friendly?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'ezj8HJEBfHw0c1uW5Eyv',\n",
       "  '_score': 11.4985075,\n",
       "  '_source': {'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'Zzj8HJEBfHw0c1uW4UzR',\n",
       "  '_score': 10.89992,\n",
       "  '_source': {'question': 'Course - When will the course start?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'aDj8HJEBfHw0c1uW4kwi',\n",
       "  '_score': 10.89992,\n",
       "  '_source': {'question': 'Course - What are the prerequisites for this course?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'aTj8HJEBfHw0c1uW4kxG',\n",
       "  '_score': 10.89992,\n",
       "  '_source': {'question': 'Course - Can I still join the course after the start date?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = es_client.search(\n",
    "    index=index_name,\n",
    "    query={\n",
    "        \"match\": {\"section\": \"General course-related questions\"},\n",
    "    },\n",
    "    knn=knn_query,\n",
    "    size=5,\n",
    "    source=[\"text\", \"section\", \"question\", \"course\"]\n",
    ")\n",
    "\n",
    "response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181df64-90b2-4c0f-99af-4d198c9f204a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
